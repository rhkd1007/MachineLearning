{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([3,3])\n",
    "m1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "브로드캐스팅(Broadcasting)크기가 다른 행렬 또는 텐서에 대해서 사칙연산을 수행할때 Python에서는 자동으로 크기를 맞춰서 연산을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector + Scalarpermalink\n",
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([3])\n",
    "m1+m2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 곱셈 & 곱셈 행렬 곱셈(.matmul) vs 원소 별 곱셈(.null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1 :  torch.Size([2, 2])\n",
      "Shape of Matrix 2 :  torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
    "m2 = torch.FloatTensor([[1],[2]])\n",
    "print('Shape of Matrix 1 : ',m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2 : ',m2.shape) # 2 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱셈(matrix mutiplication)\n",
    "m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#곱셈\n",
    "m1*m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.mul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(dim=0)) # (행, 열)에서 행(0) 제거(즉, 열 별로 평균)\n",
    "print(t.mean(dim=1)) # (행, 열)에서 열(1) 제거(즉, 행 별로 평균)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum(dim=0)) # (행, 열)에서 행(0) 제거(즉, 열 별로 덧셈)\n",
    "print(t.sum(dim=1)) # (행, 열)에서 열(1) 제거(즉, 행 별로 덧셈)\n",
    "print(t.sum(dim=-1)) # (행, 열)에서 열(-1) 제거(행 별로 덧셈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print(t.max())\n",
    "print(t.max(dim=0)) # (행, 열)에서 행(0) 제거(즉, 열 별로 최대)\n",
    "print(t.max(dim=1)) # (행, 열)에서 열(1) 제거(즉, 행 별로 최대)\n",
    "print(t.max(dim=-1)) # (행, 열)에서 열(-1) 제거(즉, 행 별로 최대)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view:원소의 수를 유지하면서 텐서의 크기변경. 파이토치 텐서의 뷰(View)는 넘파이에서의 리쉐이프(Reshape)와 같은 역할을 합니다. Reshape라는 이름에서 알 수 있듯이, 텐서의 크기(Shape)를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "torch.Size([3, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, -1]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7584\\170351586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 원소가 12개 이므로 행을 3개 유지, 즉 열은 4개 나옴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 3행 4열\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 원소가 12개 이므로 행을 5개 유지해야 하므로 오류 발생\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[5, -1]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = np.array([[[0,1,2],\n",
    "               [3,4,5]],\n",
    "              [[6,7,8],\n",
    "               [9,10,11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)\n",
    "print(ft.view([-1,3])) # 원소가 12개 이므로 열을 3개 유지, 즉 행은 4개 나옴\n",
    "print(ft.view([-1,3]).shape) # 4행 3열\n",
    "print(ft.view([3,-1])) # 원소가 12개 이므로 행을 3개 유지, 즉 열은 4개 나옴\n",
    "print(ft.view([3,-1]).shape) # 3행 4열\n",
    "print(ft.view([5,-1])) # 원소가 12개 이므로 행을 5개 유지해야 하므로 오류 발생"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3차원->3차원]\n",
    "3차원 텐서에서 3차원 텐서로 차원은 유지하되, 크기(shape)를 바꾸는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1,1,3]))\n",
    "print(ft.view([-1,1,3]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeeze:1차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ft= torch.FloatTensor([[0],[1],[2]])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n",
      "----------------\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.Tensor([0,1,2])\n",
    "print(ft.shape)\n",
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(0).shape)\n",
    "\n",
    "print('----------------')\n",
    "#view 로도 구현 가능\n",
    "print(ft.view(1,-1))\n",
    "print(ft.view(1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[[0,1,2],\n",
    "               [3,4,5]],\n",
    "               [[6,7,8],\n",
    "               [9,10,11]],\n",
    "               [[0,1,2],\n",
    "               [3,4,5]],\n",
    "               [[6,7,8],\n",
    "               [9,10,11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
